{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetroMap Visualization for Self-Organizing-Maps\n",
    "\n",
    "Authors: Simeon Macke, Julius Piso\n",
    "\n",
    "This Notebook provides a working implementation of the MetroMap visualization technique for self-organizing maps. It supports the visualization of SOMs trained with the [Java SOMToolbox](http://www.ifs.tuwien.ac.at/dm/somtoolbox/index.html) or [minisom](https://github.com/JustGlowing/minisom). The MetroMap solver implements a _branch and bound_ optimization algorithm. The algorithm only considers points that comply with the octilinearity constraints in its search space. Based on these points a number of possible solutions are generated of which the one with the lowest deviation from the original layout and the least 'sharp' bends is selected. By default the U-Matrix will be used as a background to the metro lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import pickle\n",
    "import gzip\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "from os import path\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import minisom as som\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.spatial import distance_matrix, distance\n",
    "from ipywidgets import Layout, HBox, Box, widgets, interact\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.colors\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers.clear()\n",
    "\n",
    "# Show logs in stdout\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Set the log level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Change To full width mode\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOMToolBox_Parse:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def read_weight_file(self,):\n",
    "        df = pd.DataFrame()\n",
    "        if self.filename[-3:len(self.filename)] == '.gz':\n",
    "            with gzip.open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "        else:\n",
    "            with open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "\n",
    "        file.close()            \n",
    "        return df.astype('float64'), vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _read_vector_file_to_df(self, df, file):\n",
    "        xdim, ydim, vec_dim, position = 0, 0, 0, 0\n",
    "        for byte in file:\n",
    "            line = byte.decode('UTF-8')\n",
    "            if line.startswith('$'):\n",
    "                xdim, ydim, vec_dim = self._parse_vector_file_metadata(line, xdim, ydim, vec_dim)\n",
    "                if xdim > 0 and ydim > 0 and len(df.columns) == 0:\n",
    "                    df = pd.DataFrame(index=range(0, ydim * xdim), columns=range(0, vec_dim))\n",
    "            else:\n",
    "                if len(df.columns) == 0 or vec_dim == 0:\n",
    "                    raise ValueError('Weight file has no correct Dimensional information.')\n",
    "                position = self._parse_weight_file_data(line, position, vec_dim, df)\n",
    "        return df, vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _parse_weight_file_data(self, line, position, vec_dim, df):\n",
    "        splitted=line.split(' ')\n",
    "        try:\n",
    "            df.values[position] = list(np.array(splitted[0:vec_dim]).astype(float))\n",
    "            position += 1\n",
    "        except: raise ValueError('The input-vector file does not match its unit-dimension.') \n",
    "        return  position\n",
    "\n",
    "\n",
    "    def _parse_vector_file_metadata(self, line, xdim, ydim, vec_dim):\n",
    "        splitted = line.split(' ')\n",
    "        if splitted[0] == '$XDIM':      xdim = int(splitted[1])\n",
    "        elif splitted[0] == '$YDIM':    ydim = int(splitted[1])\n",
    "        elif splitted[0] == '$VEC_DIM': vec_dim = int(splitted[1])\n",
    "        return xdim, ydim, vec_dim \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetroSolver:\n",
    "    \"\"\" Metro Map Solver\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, lines, input_grid, metro_grid=None, corner_penalties=None):\n",
    "        self.__lines = copy.deepcopy(lines)\n",
    "        if corner_penalties is None:\n",
    "            corner_penalties = [0.0, 0.7, 1.4, 4.2, 5.6]\n",
    "        if metro_grid is None:\n",
    "            metro_grid = input_grid\n",
    "        self.__input_grid = input_grid\n",
    "        self.__metro_grid = metro_grid\n",
    "        self.__scale = np.array([mg / ig for ig, mg in zip(self.__input_grid, self.__metro_grid)])\n",
    "\n",
    "        self.__raw_solution = None\n",
    "        self.__solution = None\n",
    "        \n",
    "        if not isinstance(corner_penalties, list):\n",
    "            raise TypeError('`penalties` has to be a list of numbers')\n",
    "        if not np.all([isinstance(i, float) or isinstance(i, int) for i in corner_penalties]):\n",
    "            raise TypeError('`penalties` has to be a list of numbers')\n",
    "        if not len(corner_penalties) == 5:\n",
    "            raise ValueError('`penalties` has to have exactly 5 elements')\n",
    "        self.__corner_penalties = corner_penalties\n",
    "\n",
    "\n",
    "    def __transform(self, input_data):\n",
    "        \"\"\" Transform into metro grid coordinates\n",
    "        \n",
    "        Utility function to transform a list of lines from input grid coordinates into \n",
    "        metro grid coordinates.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data, list):\n",
    "            return [self.__scale * line for line in input_data]\n",
    "        elif isinstance(input_data, np.ndarray):\n",
    "            return self.__scale * input_data\n",
    "        else:\n",
    "            raise ValueError(f'Transforming the coordinates contained in a {type(input_data)}'\n",
    "                             ' is currently not supported.')\n",
    "\n",
    "\n",
    "    def __inverse_transform(self, input_data):\n",
    "        \"\"\" Transform into input grid coordinates\n",
    "        \n",
    "        Utility function to transform a list of lines from metro grid coordinates into \n",
    "        input grid coordinates.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data, list):\n",
    "            return [line / self.__scale for line in input_data]\n",
    "        elif isinstance(input_data, np.ndarray):\n",
    "            return input_data / self.__scale\n",
    "        else:\n",
    "            raise ValueError(f'Transforming the coordinates contained in a {type(input_data)}'\n",
    "                             ' is currently not supported.')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __neighborhood_generator():\n",
    "        \"\"\"Sequentially point generator\n",
    "        \n",
    "        Here we generate 2D points at discrete positions starting from the origin.\n",
    "        The generated points are spiraling outwards towards infinity.\n",
    "        \"\"\"\n",
    "        r = 1\n",
    "        pos = np.array([0,0])\n",
    "        directions = [np.array([1,0]), np.array([0,-1]), np.array([-1,0]), np.array([0,1])]\n",
    "        d_idx = 0\n",
    "        yield pos\n",
    "        pos = np.array([0,r])\n",
    "        yield pos\n",
    "        while True:\n",
    "            if np.abs(pos[0]) == np.abs(pos[1]): # corner\n",
    "                if d_idx == 3: # completed 4th direction\n",
    "                    r += 1\n",
    "                    d_idx = 0\n",
    "                    pos[1] = r\n",
    "                    yield pos\n",
    "                    continue\n",
    "                d_idx += 1\n",
    "            pos = pos + directions[d_idx]\n",
    "            yield pos\n",
    "\n",
    "\n",
    "    def __gen_neighbors(self, pt, n_neighbors = 5):\n",
    "        \"\"\" Generate Neighbor candidates\n",
    "        \n",
    "        Here we generate a list of possible neighbors for the provided point.\n",
    "        This function \n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "        nearest = np.round(pt)\n",
    "\n",
    "        for offset in self.__neighborhood_generator():\n",
    "            new_pt = nearest + offset\n",
    "\n",
    "            neighbors.append((new_pt, np.linalg.norm(new_pt-pt)))\n",
    "            if len(neighbors) >= n_neighbors:\n",
    "                break\n",
    "\n",
    "        neighbors.sort(key=lambda a: a[1])\n",
    "        return neighbors\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_sector(v1, v2):\n",
    "        \"\"\" Returns the octilinear sector of v2 relative to v1\n",
    "        \n",
    "        Determines the octilinear sector of v2 relative to v1. The code is based\n",
    "        on a similar calculation in the MetroMapVisualizer.java which is part of\n",
    "        the Java SOMToolbox (http://www.ifs.tuwien.ac.at/dm/somtoolbox/index.html)\n",
    "        \n",
    "        The numbering of the different sectors is as follows (v1 in the center):\n",
    "            3  2  1\n",
    "            4 -1  0\n",
    "            5  6  7\n",
    "        \"\"\"\n",
    "\n",
    "        if v1[0] < v2[0] and v1[1] == v2[1]:   # right\n",
    "            return 0\n",
    "        elif v1[0] < v2[0] and v1[1] < v2[1]:  # right up\n",
    "            return 1\n",
    "        elif v1[0] == v2[0] and v1[1] < v2[1]: # up\n",
    "            return 2\n",
    "        elif v1[0] > v2[0] and v1[1] < v2[1]:  # left up\n",
    "            return 3\n",
    "        elif v1[0] > v2[0] and v1[1] == v2[1]: # left\n",
    "            return 4\n",
    "        elif v1[0] > v2[0] and v1[1] > v2[1]:  # left down\n",
    "            return 5\n",
    "        elif v1[0] == v2[0] and v1[1] > v2[1]: # down\n",
    "            return 6\n",
    "        elif v1[0] < v2[0] and v1[1] > v2[1]:  # right down\n",
    "            return 7\n",
    "        if np.any(v1 != v2):\n",
    "            print(v1, v2)\n",
    "\n",
    "        # points equal\n",
    "        return -1 \n",
    "\n",
    "\n",
    "    def __calc_penalty(self, sector_diff):\n",
    "        \"\"\" Calculate a penalty for line bends\n",
    "        \n",
    "        Calculates a penalty based on the sector difference of two edges.\n",
    "        A penalty of 3 makes the specific configuration as undesirable as a node\n",
    "        that's 3 cells apart. Closer solutions are favored in the final selection.\n",
    "        \"\"\"\n",
    "        if sector_diff == 4:\n",
    "            return self.__corner_penalties[4]\n",
    "\n",
    "        sector_diff = np.mod(sector_diff, 4)\n",
    "        if sector_diff == 0:\n",
    "            return self.__corner_penalties[0]\n",
    "        elif sector_diff == 1:\n",
    "            return self.__corner_penalties[1]\n",
    "        elif sector_diff == 2:\n",
    "            return self.__corner_penalties[2]\n",
    "        elif sector_diff == 3:\n",
    "            return self.__corner_penalties[3]\n",
    "\n",
    "\n",
    "    def __gen_feasible_neighbors(self, snapped, pt, n_neighbors = 4):\n",
    "        # search more neighbors than return, increases quality of neighbors with a \n",
    "        # relatively small additional computational effort\n",
    "        MULTIPLIER = 2\n",
    "\n",
    "        neighbors = []\n",
    "        nearest = np.round(pt)\n",
    "        prev = snapped[-1]\n",
    "\n",
    "        prev_direction = None\n",
    "        prev_sector = None\n",
    "        if len(snapped) > 1:\n",
    "            prev_sector = self.__get_sector(snapped[-2], snapped[-1])\n",
    "\n",
    "        for offset in self.__neighborhood_generator():\n",
    "            new_pt = nearest + offset\n",
    "\n",
    "            diff = np.abs(new_pt - prev)\n",
    "            if new_pt[0] == prev[0] or new_pt[1] == prev[1] or diff[0] == diff[1]:\n",
    "                penalty = 0\n",
    "                if prev_sector is not None:\n",
    "                    new_sector = self.__get_sector(prev, new_pt)\n",
    "                    abs_sec_diff = np.abs(new_sector - prev_sector)\n",
    "                    penalty = self.__calc_penalty(abs_sec_diff)\n",
    "\n",
    "                dist = np.linalg.norm(new_pt - prev)\n",
    "                if dist >= 1:\n",
    "                    neighbors.append((new_pt, np.linalg.norm(new_pt - pt) + penalty))\n",
    "\n",
    "            if len(neighbors) >= n_neighbors * MULTIPLIER:\n",
    "                break\n",
    "\n",
    "        neighbors.sort(key=lambda a: a[1])\n",
    "        return neighbors[:n_neighbors]\n",
    "\n",
    "\n",
    "    def __snap_line(self, line, snapped, dist, lb, n_neighbors):\n",
    "        if len(line) == 0:\n",
    "            return dist, snapped\n",
    "        pt = line[0]\n",
    "        best_line = None\n",
    "        best = None\n",
    "        neighbors = self.__gen_feasible_neighbors(snapped, pt, n_neighbors)\n",
    "        for n_pt, n_dist in neighbors:\n",
    "            if (dist + n_dist) > lb:\n",
    "                continue\n",
    "            n_snapped = snapped[:]\n",
    "            n_snapped.append(n_pt)\n",
    "            total_dist, new_snapped = self.__snap_line(line[1:], n_snapped, dist + n_dist, lb, n_neighbors)\n",
    "            if total_dist is not None and total_dist < lb:\n",
    "                lb = total_dist\n",
    "                best = total_dist\n",
    "                best_line = new_snapped\n",
    "        return best, best_line\n",
    "\n",
    "\n",
    "    def solve(self, n_neighbors=4, start_neighbors=5):\n",
    "        \"\"\" Solves the Metro Map for the provided lines\n",
    "        \n",
    "        For each point of each line the solver applies a neighborhood search strategy that\n",
    "        tries to stay as true as possible to the original station positions while still\n",
    "        complying to the octilinearity constraints.\n",
    "        \"\"\"\n",
    "        dist_threshold = 3\n",
    "        snapped_lines = []\n",
    "        lines = self.__transform(self.__lines)\n",
    "        for idx, line in enumerate(lines):\n",
    "            logging.info(f\"snapping line {idx+1}/{len(self.__lines)}\")\n",
    "            start = line[0]\n",
    "            neighbors = self.__gen_neighbors(start, start_neighbors)\n",
    "            best_dist = 999999\n",
    "            snapped = None\n",
    "            for pt, dist in neighbors:\n",
    "                n_dist, n_snapped = self.__snap_line(line[1:], [pt], dist, best_dist, n_neighbors)\n",
    "                if n_dist is None:\n",
    "                    continue\n",
    "                if n_dist < best_dist:\n",
    "                    #print(n_snapped)\n",
    "                    best_dist = n_dist\n",
    "                    snapped = n_snapped\n",
    "            \n",
    "            snapped_lines.append(snapped)\n",
    "\n",
    "        self.__raw_solution = snapped_lines\n",
    "\n",
    "\n",
    "    def post_process(self, overlap_shift):\n",
    "        \"\"\" Post processing\n",
    "        \n",
    "        Move overlapping metro lines so that each individual line is visible in the final\n",
    "        plot. Also creates a list of crossover stations and their corresponding line directions\n",
    "        which can later be used during the visualization step.\n",
    "        \"\"\"\n",
    "    \n",
    "        if self.__raw_solution is None:\n",
    "            logger.warning('The solve method has to be called before any post processing can be done.')\n",
    "            return\n",
    "        \n",
    "        lines = copy.deepcopy(self.__raw_solution)\n",
    "        stations = defaultdict(lambda: np.array([0,0,0,0]))\n",
    "\n",
    "        # These vectors specify the octilinear base directions. Their index corresponds\n",
    "        # to the value of the sector.\n",
    "        orientation_vectors = [\n",
    "            np.array([1,0]),\n",
    "            np.array([1,1]),\n",
    "            np.array([0,1]),\n",
    "            np.array([-1,1]),\n",
    "            np.array([-1,0]),\n",
    "            np.array([-1,-1]),\n",
    "            np.array([0,-1]),\n",
    "            np.array([1, -1])\n",
    "        ]\n",
    "        \n",
    "        # These vectors are the normalized orthogonal directions to the first four octilinear\n",
    "        # directions.\n",
    "        inv_sqrt = 1/np.sqrt(2)\n",
    "        shift_vectors = [\n",
    "            np.array([0,1]),\n",
    "            np.sqrt(2) * np.array([0,1]),\n",
    "            np.array([-1,0]),\n",
    "            np.sqrt(2) * np.array([0,-1])\n",
    "        ]\n",
    "        \n",
    "        grid = defaultdict(lambda: [])\n",
    "        rank = {}\n",
    "        \n",
    "        for lidx, line in enumerate(lines):\n",
    "            for sidx, (a,b) in enumerate(zip(line[:-1], line[1:])):\n",
    "                orientation = self.__get_sector(a, b)\n",
    "                current = np.copy(a)\n",
    "                vector = orientation_vectors[orientation]\n",
    "                logger.debug(f\"curr: {current} vector: {vector} b {b} orientation {orientation}\")\n",
    "                \n",
    "                # First iterate over each grid point between the station a and the next station b\n",
    "                # and find the maximum number of collinear edges (edges that run in the same\n",
    "                # direction or in reverse) throughout the path between the two stations.\n",
    "                max_collinear = 0\n",
    "                while not np.all(np.isclose(current, b, rtol = 0.01)):\n",
    "                    n_collinear_edges = len(grid[(tuple(current), orientation % 4)])\n",
    "                    if n_collinear_edges > max_collinear:\n",
    "                        max_collinear = n_collinear_edges\n",
    "                    \n",
    "                    # Move to the next grid point\n",
    "                    current += vector\n",
    "\n",
    "                logger.debug(f'max shift {max_collinear}')\n",
    "                \n",
    "                # Store the maximum number of collinear lines that are associated to this particular\n",
    "                # metro line (identified by the line index lidx) and edge (identified by the first\n",
    "                # stop of that particular edge) of that metro line, as well as its orientation.\n",
    "                # We also update this number of collinear lines for all preceeding stops of this\n",
    "                # particular line, which lie on a straight line with the current edge.\n",
    "                if (lidx, sidx, orientation % 4) in rank:\n",
    "                    i = sidx\n",
    "                    while (lidx, i, orientation % 4) in rank:\n",
    "                        if rank[(lidx, i, orientation % 4)] < max_collinear + 1:\n",
    "                            rank[(lidx, i, orientation % 4)] = max_collinear + 1\n",
    "                        i -= 1\n",
    "                else:\n",
    "                    rank[(lidx, sidx, orientation % 4)] = max_collinear + 1\n",
    "                \n",
    "                # Also update the next station's rank\n",
    "                rank[(lidx, sidx+1, orientation % 4)] = max_collinear + 1\n",
    "\n",
    "                # Then iterate over those grid points between the two consecutive stations again\n",
    "                # and this time assign the maximum number of collinear edges we obtained during the \n",
    "                # last step to the actual grid positions.\n",
    "                current = np.copy(a)\n",
    "                while not np.all(np.isclose(current, b, rtol = 0.01)):\n",
    "                    grid[(tuple(current), orientation % 4)].append(True)\n",
    "                    current += vector\n",
    "                    \n",
    "                # stations\n",
    "                transformed_pt = self.__inverse_transform(a)\n",
    "                stations[tuple(transformed_pt)][orientation % 4] = stations[tuple(transformed_pt)][orientation % 4] + 1\n",
    "                if sidx == len(line) - 2:\n",
    "                    transformed_pt = self.__inverse_transform(b)\n",
    "                    stations[tuple(transformed_pt)][orientation % 4] = stations[tuple(transformed_pt)][orientation % 4] + 1\n",
    "\n",
    "        for (lidx, s, orientation), n in rank.items():\n",
    "            if n > 1:\n",
    "                f = (n % 2) * 2 - 1\n",
    "                shift = shift_vectors[orientation] * f * int(n/2) * overlap_shift\n",
    "                lines[lidx][s] = lines[lidx][s] + self.__transform(shift)\n",
    "                \n",
    "\n",
    "        self.__solution = lines\n",
    "        self.stations = stations\n",
    "    \n",
    "    \n",
    "    def get_raw_solution(self):\n",
    "        if self.__raw_solution is not None:\n",
    "            return self.__inverse_transform(self.__raw_solution)\n",
    "        else:\n",
    "            logger.warning('Solver has yet to be run. No solution available.')\n",
    "\n",
    "\n",
    "    def get_solution(self):\n",
    "        if self.__solution is not None:\n",
    "            return self.__inverse_transform(self.__solution)\n",
    "        else:\n",
    "            logger.warning('Postprocessing has yet to be run. No solution available.')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomViz:\n",
    "\n",
    "    def __init__(self, weights=[], m=None, n=None):\n",
    "        self.weights = weights\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        \n",
    "        # Params for the metro visualization\n",
    "        self.solver_params = None\n",
    "        self.postprocessing_params = None\n",
    "        self.lines = None\n",
    "        self.metro_lines = None\n",
    "        self.stops = None\n",
    "        self.solver = None\n",
    "        self.metro_grid = None\n",
    "        self.corner_penalties = None\n",
    "\n",
    "\n",
    "    def umatrix(self, som_map=None, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        um =np.zeros((self.m *self.n, 1))\n",
    "        neuron_locs = list()\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                neuron_locs.append(np.array([i, j]))\n",
    "        neuron_distmat = distance_matrix(neuron_locs,neuron_locs)\n",
    "\n",
    "        for i in range(self.m * self.n):\n",
    "            neighbor_idxs = neuron_distmat[i] <= 1\n",
    "            neighbor_weights = self.weights[neighbor_idxs]\n",
    "            um[i] = distance_matrix(np.expand_dims(self.weights[i], 0), neighbor_weights).mean()\n",
    "\n",
    "        if som_map is None:\n",
    "            return self.plot(um.reshape(self.m,self.n), color=color, interp=interp, title=title)    \n",
    "        else:\n",
    "            som_map.data[0].z = um.reshape(self.m,self.n)\n",
    "\n",
    "\n",
    "    def hithist(self, som_map=None, idata = [], color='RdBu', interp = \"best\", title=\"\"):\n",
    "        hist = [0] *self.n *self.m\n",
    "        for v in idata: \n",
    "            position =np.argmin(np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1)))\n",
    "            hist[position] += 1    \n",
    "        \n",
    "        if som_map is None:\n",
    "            return self.plot(np.array(hist).reshape(self.m,self.n), color=color, interp=interp, title=title)        \n",
    "        else:\n",
    "            som_map.data[0].z = np.array(hist).reshape(self.m,self.n)\n",
    "\n",
    "\n",
    "    def component_plane(self, som_map=None, component=0, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        if som_map is None:\n",
    "            return self.plot(\n",
    "                self.weights[:,component].reshape(-1,self.n), color=color, interp=interp, title=title)   \n",
    "        else:\n",
    "            som_map.data[0].z = self.weights[:,component].reshape(-1,n)\n",
    "\n",
    "\n",
    "    def sdh(self, som_map=None, idata=[], sdh_type=1, factor=1, draw=True, color=\"Cividis\", interp = \"best\", title=\"\"):\n",
    "\n",
    "        import heapq\n",
    "        sdh_m = [0] *self.m *self.n\n",
    "\n",
    "        cs=0\n",
    "        for i in range(0,factor): cs += factor-i\n",
    "\n",
    "        for vector in idata:\n",
    "            dist = np.sqrt(np.sum(np.power(self.weights - vector, 2), axis=1))\n",
    "            c = heapq.nsmallest(factor, range(len(dist)), key=dist.__getitem__)\n",
    "            if (sdh_type==1): \n",
    "                for j in range(0,factor):  sdh_m[c[j]] += (factor-j)/cs # normalized\n",
    "            if (sdh_type==2):\n",
    "                for j in range(0,factor): sdh_m[c[j]] += 1.0/dist[c[j]] # based on distance\n",
    "            if (sdh_type==3): \n",
    "                dmin = min(dist)\n",
    "                for j in range(0,factor): sdh_m[c[j]] += 1.0 - (dist[c[j]]-dmin)/(max(dist)-dmin)  \n",
    "\n",
    "        if som_map==None: return self.plot(np.array(sdh_m).reshape(-1,self.n), color=color, interp=interp, title=title)      \n",
    "        else: som_map.data[0].z = np.array(sdh_m).reshape(-1,self.n)\n",
    "\n",
    "\n",
    "    def project_data(self,som_m=None, idata=[], title=\"\"):\n",
    "        data_y = []\n",
    "        data_x = []\n",
    "        for v in idata:\n",
    "            position =np.argmin(np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1)))\n",
    "            x,y = position % self.n, position // self.n\n",
    "            data_x.extend([x])\n",
    "            data_y.extend([y])\n",
    "            \n",
    "        if som_m!=None: som_m.add_trace(go.Scatter(x=data_x, y=data_y, mode = \"markers\", marker_color='rgba(255, 255, 255, 0.8)',))\n",
    "\n",
    "\n",
    "    def time_series(self, som_m=None, idata=[], wsize=50, title=\"\"): #not tested\n",
    "             \n",
    "        data_y = []\n",
    "        data_x = [i for i in range(0,len(idata))]\n",
    "        \n",
    "        data_x2 = []\n",
    "        data_y2 = []\n",
    "        \n",
    "        qmin = np.Inf\n",
    "        qmax = 0\n",
    "        \n",
    "        step=1\n",
    "        \n",
    "        ps = []\n",
    "        for v in idata:\n",
    "            matrix = np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1))\n",
    "            position = np.argmin(matrix)\n",
    "            qerror = matrix[position]\n",
    "            if qmin>qerror: qmin = qerror\n",
    "            if qmax<qerror: qmax = qerror\n",
    "            ps.append((position, qerror))\n",
    "       \n",
    "        markerc=[]    \n",
    "        for v in ps:\n",
    "            data_y.extend([v[0]])\n",
    "            rez = v[1]/qmax\n",
    " \n",
    "            markerc.append('rgba(0, 0, 0, '+str(rez)+')') \n",
    "            \n",
    "            x,y = v[0] % self.n, v[0] // self.n \n",
    "            if    x==0: y = np.random.uniform(low=y, high=y+.1)\n",
    "            elif  x==self.m-1: y = np.random.uniform(low=y-.1, high=y)\n",
    "            elif  y==0: x = np.random.uniform(low=x, high=x+.1)\n",
    "            elif  y==self.n-1: x = np.random.uniform(low=x-.1, high=x)\n",
    "            else: x,y = np.random.uniform(low=x-.1, high=x+.1), np.random.uniform(low=y-.1, high=y+.1)                           \n",
    "            \n",
    "            data_x2.extend([x])\n",
    "            data_y2.extend([y]) \n",
    "    \n",
    "        ts_plot = go.FigureWidget(go.Scatter(x=[], y=[], mode = \"markers\", marker_color=markerc, marker=dict(colorscale='Viridis', showscale=True, color=np.random.randn(500))))\n",
    "        ts_plot.update_xaxes(range=[0, wsize])       \n",
    "\n",
    "        \n",
    "        ts_plot.data[0].x, ts_plot.data[0].y = data_x, data_y\n",
    "        som_m.add_trace(go.Scatter(x=data_x2, y=data_y2, mode = \"markers\",))\n",
    "  \n",
    "        som_m.layout.height = 500\n",
    "        ts_plot.layout.height = 500\n",
    "        som_m.layout.width = 500\n",
    "        ts_plot.layout.width = 1300\n",
    "        \n",
    "        return HBox([go.FigureWidget(som_m), go.FigureWidget(ts_plot)])\n",
    "\n",
    "\n",
    "    def __gen_sequential_colors(self, levels, colors=px.colors.sequential.Jet):\n",
    "        \"\"\"Generate a color sequence\n",
    "        \n",
    "        Generates a color sequence with the specified number of levels based on the\n",
    "        provided continuous colormap.\n",
    "        \"\"\"\n",
    "        color_sequence = []\n",
    "        n_colors = len(colors)\n",
    "        n_levels = levels\n",
    "\n",
    "        color_sequence.append(colors[0])\n",
    "\n",
    "        if n_colors > 1:\n",
    "            color_step = 1 / (n_colors - 1)\n",
    "        else:\n",
    "            return color_sequence * n_levels\n",
    "    \n",
    "        for i in range(1, n_levels-1):\n",
    "            level_pos = i / (n_levels - 1)\n",
    "            color_index = int(level_pos/color_step)\n",
    "\n",
    "            intermediate = (level_pos - color_index * color_step)/color_step\n",
    "            color_sequence.append(\n",
    "                plotly.colors.find_intermediate_color(\n",
    "                    colors[color_index], colors[color_index+1],\n",
    "                    intermediate, colortype='rgb'))\n",
    "\n",
    "        color_sequence.append(colors[-1])\n",
    "        return color_sequence\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_crossover_station_shape(pos=np.array([0,0]), scale=1, lines_per_sector=np.array([1,0,0,0])):\n",
    "        leading_sectors = np.argwhere(lines_per_sector == np.max(lines_per_sector)).flatten()\n",
    "        print(f\"leading: {leading_sectors}\")\n",
    "        \n",
    "        sector = 0\n",
    "        if len(leading_sectors) == 1:\n",
    "            sector = (leading_sectors[0] + 2) % 4\n",
    "        elif len(leading_sectors) == 2:\n",
    "            secdiff = np.abs(leading_sectors[0] - leading_sectors[1]) % 3\n",
    "            print(f\"secdiff: {secdiff}\")\n",
    "            if secdiff == 0:\n",
    "                sector = (leading_sectors[0] + 2) % 4\n",
    "            elif secdiff == 1:\n",
    "                sector = np.where(lines_per_sector != lines_per_sector[leading_sectors[0]])[0][0]\n",
    "            elif secdiff == 2:\n",
    "                sector = (leading_sectors[0] + 1) % 4\n",
    "        if len(leading_sectors) == 3:\n",
    "            sector = np.argmin(lines_per_sector)\n",
    "            \n",
    "        print(f'lps: {lines_per_sector}')\n",
    "        print(f\"sector: {sector}\")\n",
    "\n",
    "        w = 1\n",
    "        h = .5\n",
    "        r = np.min([0.3, h/2, w/2])\n",
    "\n",
    "        p = np.array([\n",
    "            [-w/2+r, -h/2  ],\n",
    "            [w/2-r,  -h/2  ],\n",
    "            [w/2,    -h/2  ],\n",
    "            [w/2,    -h/2+r],\n",
    "            [w/2,    h/2-r ],\n",
    "            [w/2,    h/2   ],\n",
    "            [w/2-r,  h/2   ],\n",
    "            [-w/2+r, h/2   ],\n",
    "            [-w/2,   h/2   ],\n",
    "            [-w/2,   h/2-r ],\n",
    "            [-w/2,   -h/2+r],\n",
    "            [-w/2,   -h/2  ],\n",
    "            [-w/2+r, -h/2  ],\n",
    "        ])\n",
    "\n",
    "        sector_to_degree = {\n",
    "            0: -90,\n",
    "            1: 45,\n",
    "            2: 0,\n",
    "            3: -45,\n",
    "        }\n",
    "\n",
    "        phi = np.radians(sector_to_degree[sector % 4])\n",
    "\n",
    "        A = np.array([\n",
    "            [np.cos(phi), -np.sin(phi)],\n",
    "            [np.sin(phi), np.cos(phi)],\n",
    "        ])\n",
    "\n",
    "        p = pos + scale*(A@(p.T)).T\n",
    "\n",
    "        return f\"\"\"\n",
    "                M {p[0,0]} {p[0,1]}\n",
    "                L {p[1,0]} {p[1,1]}\n",
    "                Q {p[2,0]} {p[2,1]} {p[3,0]} {p[3,1]}\n",
    "                L {p[4,0]} {p[4,1]}\n",
    "                Q {p[5,0]} {p[5,1]} {p[6,0]} {p[6,1]}\n",
    "                L {p[7,0]} {p[7,1]}\n",
    "                Q {p[8,0]} {p[8,1]} {p[9,0]} {p[9,1]}\n",
    "                L {p[10,0]} {p[10,1]}\n",
    "                Q {p[11,0]} {p[11,1]} {p[0,0]} {p[0,1]}\n",
    "                Z\"\"\"\n",
    "\n",
    "\n",
    "    def __prepare_metro(self, stops, metro_grid, corner_penalties, postprocess, overlap_shift):\n",
    "        if self.lines is None or stops != self.stops:\n",
    "            self.lines = []\n",
    "            n_lines = self.weights.shape[1]\n",
    "            for component in range(n_lines):\n",
    "                # Reshape the weights into a 2D array with the dimension (m, n)\n",
    "                raw = self.weights[:,component].reshape(self.m, self.n)\n",
    "                # Create a list of values that uniformly divide the range between the\n",
    "                # minimum and the maximum value of the component weights into 'stops+1'\n",
    "                # intervals.\n",
    "                ranges = np.linspace(raw.min(), raw.max(), stops+1)\n",
    "                # Digitize the weights array, so that only 'stops' different values\n",
    "                # are possible. The value of each element in the resulting grid\n",
    "                # corresponds to the index of the interval, starting with 1.\n",
    "                binned = np.digitize(raw, ranges)\n",
    "                \n",
    "                stations = []\n",
    "                for i in range(1, stops+1):\n",
    "                    # Find the positions inside the digitized array, where the elements\n",
    "                    # have the value of the current level i\n",
    "                    match = np.argwhere(binned == i)\n",
    "                    if match.shape[0] == 0:\n",
    "                        logging.info(\"layer empty\")\n",
    "                        continue\n",
    "                    # Summing up all matches from above, which are provided as an array of\n",
    "                    # coordinates, and dividing them by the number of matches gives us the\n",
    "                    # center of gravity for that particular level.\n",
    "                    stations.append(np.sum(match, axis=0)/match.shape[0])\n",
    "                self.lines.append(stations)\n",
    "\n",
    "        solver_activated = False\n",
    "        if (stops != self.stops or metro_grid != self.metro_grid\n",
    "            or corner_penalties != self.corner_penalties):\n",
    "            logger.info('Solving...')\n",
    "\n",
    "            self.solver = MetroSolver(\n",
    "                lines=self.lines, input_grid=(self.m, self.n), metro_grid=metro_grid,\n",
    "                corner_penalties=corner_penalties)\n",
    "\n",
    "            self.solver.solve()\n",
    "            solver_activated = True\n",
    "\n",
    "        if postprocess == True and (solver_activated == True\n",
    "                                    or overlap_shift != self.overlap_shift):\n",
    "            logger.info('Postprocessing ...')\n",
    "            self.solver.post_process(overlap_shift=overlap_shift)\n",
    "\n",
    "        if postprocess:\n",
    "            self.metro_lines = self.solver.get_solution()\n",
    "        else:\n",
    "            self.metro_lines = self.solver.get_raw_solution()\n",
    "\n",
    "        self.stops = stops\n",
    "        self.metro_grid = metro_grid\n",
    "        self.overlap_shift = overlap_shift\n",
    "        self.corner_penalties = corner_penalties\n",
    "\n",
    "\n",
    "    def metro(self, som_map=None, stops=6, water_level=0.33, linewidth=6, snapping_overlay=True,\n",
    "              metro_grid=None, corner_penalties=None, postprocess=True, overlap_shift=0.5):\n",
    "        \"\"\" MetroMap Visualization\n",
    "        \n",
    "        Visualizes the gradient of the component layers by building metro lines based on the\n",
    "        discretized levels of each of the components. Can be helpful in understanding the\n",
    "        influence attributes have on the formation of clusterings, as well as their correlations\n",
    "        among each other.\n",
    "\n",
    "        Args:\n",
    "          som_map (plotly.FigureWidget): if this parameter is provided, the metro lines will be\n",
    "              on top of this visualization instead of the UMatrix.\n",
    "          stops (int): The number of stops/bins the metro lines should have\n",
    "          water_level (float): a number between 0 and 1 that sets the threshold at which the values\n",
    "              from the UMatrix plot should be represented using blue coloring.\n",
    "          linewidth (float): how wide the metro lines should be in the final plot.\n",
    "          snapping_overlay (bool): whether to draw the metro lines or the raw, unconstrained metro\n",
    "              stops obtained by binning the component layers.\n",
    "          metro_grid (tuple): specifies the grid size of the metro line. This parameter allows the\n",
    "              metro solver to create a metro network at a different resolution than that of the SOM.\n",
    "              If the parameter is left out/None the resolution of the SOM will be used instead.\n",
    "          corner_penalties (list): a list of exactly five floats. Each element corresponds to the\n",
    "              penalty weight that should be applied to bends between two consecutive edges of the\n",
    "              metro line. The first element corresponds to the edges forming a straight line, the\n",
    "              second element is used when the edges form an angle of 45°, and so on. The fifth\n",
    "              element is the penalty that should be applied when an edge returns in the same\n",
    "              direction as it came from.\n",
    "          postprocess (bool): Whether or not to apply postprocessing.\n",
    "          overlap_shift (float): The amount stations get shifted during postprocessing when they\n",
    "              overlap.\n",
    "        \n",
    "        Returns:\n",
    "          Plotly FigureWidget\n",
    "        \"\"\"\n",
    "        water_level = np.clip(water_level, 0, 1)\n",
    "        water = [\n",
    "            (0.0, 'rgb(255,255,255)'),\n",
    "            (water_level, 'rgb(255,255,255)'),\n",
    "            (water_level, 'rgb(198,219,239)'),\n",
    "            (1.0, 'rgb(198,219,239)')\n",
    "        ]\n",
    "\n",
    "        self.__prepare_metro(stops, metro_grid, corner_penalties, postprocess, overlap_shift)\n",
    "\n",
    "        if som_map is None:\n",
    "            som_map = self.umatrix(color=water, interp='best', title='MetroMap') \n",
    "\n",
    "        colors = self.__gen_sequential_colors(len(self.lines), colors=px.colors.diverging.Portland)\n",
    "        \n",
    "        if not snapping_overlay:\n",
    "            for i, (line, col) in enumerate(zip(self.lines, colors)):\n",
    "                y, x = list(zip(*line))\n",
    "                som_map.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=x, y=y, mode='lines+markers', name=f'Component {i}',\n",
    "                        line_shape='linear', line=dict(width=linewidth, dash='dot', color=col),\n",
    "                        marker=dict(size=linewidth, color='white', line=dict(width=linewidth/3, color='black'))))\n",
    "        else:\n",
    "            for i, (line, col) in enumerate(zip(self.metro_lines, colors)):\n",
    "                y, x = list(zip(*line))\n",
    "                som_map.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=x, y=y, mode='lines+markers', name=f'Component {i}', line_shape='linear',\n",
    "                        line=dict(width=linewidth, color=col),\n",
    "                        marker=dict(size=linewidth, color='white', line=dict(width=linewidth/3, color='black'))))\n",
    "                # Add special markers to the endstop corresponding to the highest component value\n",
    "                som_map.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[x[0]], y=[y[0]], mode='markers', marker_symbol='circle-x', showlegend=False,\n",
    "                        line=dict(width=linewidth, color=col), \n",
    "                        marker=dict(size=linewidth, color='white', line=dict(width=linewidth/3, color='black'))))\n",
    "\n",
    "\n",
    "            shapes = []\n",
    "            for (y, x), station_sizes in self.solver.stations.items():\n",
    "                abs_size = np.sum(station_sizes)\n",
    "                if abs_size > 1:\n",
    "                    shapes.append(dict(\n",
    "                        type=\"path\",\n",
    "                        path=self.generate_crossover_station_shape(\n",
    "                            pos=np.array([x, y]),\n",
    "                            scale=np.max([self.m, self.n])/28,\n",
    "                            lines_per_sector=station_sizes),\n",
    "                        line_color=\"black\",\n",
    "                        fillcolor=\"white\",\n",
    "                        line=dict(width=linewidth/3, color='black')))\n",
    "\n",
    "            if shapes:\n",
    "                som_map.update_layout(shapes=shapes)\n",
    "        return som_map\n",
    "\n",
    "\n",
    "    def plot(self, matrix, color=\"Viridis\",interp = \"none\", title=\"\", width=1000, height=900, showscale=False):\n",
    "        return go.FigureWidget(\n",
    "            go.Heatmap(z=matrix, zsmooth=interp, showscale=showscale, colorscale=color),\n",
    "            layout=go.Layout(\n",
    "                width=1000, height=900, title=title, title_x=0.5, plot_bgcolor='rgb(255,255,255)',\n",
    "                yaxis=dict(scaleanchor=\"x\", scaleratio=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Chainlink Dataset (trained with SOMToolbox)\n",
    "\n",
    "For this example we visualize a SOM that was trained on the [chainlink dataset](http://www.ifs.tuwien.ac.at/dm/somtoolbox/datasets.html) using the SOMToolbox. The SOM we trained has a dimension of 40x20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chainlink_viz():\n",
    "    smap = SOMToolBox_Parse(path.join('pretrained', 'chainlink', 'chainlink_small.wgt.gz'))\n",
    "    smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "    return SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)\n",
    "\n",
    "viz_chainlink = chainlink_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we show the raw lines (without applying the MetroSolver) as a reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_chainlink.metro(\n",
    "    stops=6,\n",
    "    water_level=0.2,\n",
    "    overlap_shift=1,\n",
    "    snapping_overlay=False,\n",
    "    linewidth=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plot the lines with the same number of bins, but this time with applying the MetroSolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_chainlink.metro(\n",
    "    stops=6,\n",
    "    water_level=0.2,\n",
    "    overlap_shift=1,\n",
    "    snapping_overlay=True,\n",
    "    linewidth=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we test what the result would have been, if no penalties were applied on sections with sharp bends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_chainlink.metro(\n",
    "    stops=6,\n",
    "    water_level=0.2,\n",
    "    overlap_shift=1,\n",
    "    snapping_overlay=True,\n",
    "    corner_penalties=[0, 0, 0, 0, 0],\n",
    "    linewidth=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Chainlink Dataset (trained with MiniSOM)\n",
    "\n",
    "For the second example we directly train a SOM in the notebook by using the minisom package. We train the SOM on the chainlink dataset, and use a size of 40x20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chainlink_raw():\n",
    "    chainlink = SOMToolBox_Parse(path.join('pretrained', 'chainlink', 'chainlink.vec'))\n",
    "    idata, idim, idata_x, idata_y = chainlink.read_weight_file()\n",
    "\n",
    "    # Pre-Process dataset\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    dat = min_max_scaler.fit_transform(idata)\n",
    "    return dat\n",
    "chainlink_data = load_chainlink_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minisom_m = 40\n",
    "minisom_n = 20\n",
    "\n",
    "# Train SOM\n",
    "s = som.MiniSom(minisom_m, minisom_n, chainlink_data.shape[1], sigma=6, learning_rate=0.7)\n",
    "s.train_random(chainlink_data, 1000000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizaton\n",
    "viz_chainlink_mini = SomViz(s._weights.reshape(-1,3), minisom_m, minisom_n)\n",
    "display(viz_chainlink_mini.umatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_chainlink_mini.metro(\n",
    "    stops=7,\n",
    "    water_level=0.7,\n",
    "    overlap_shift=1,\n",
    "    snapping_overlay=True,\n",
    "    linewidth=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: 10clusters Dataset (trained with SOMToolbox)\n",
    "\n",
    "This example shows how the visualization holds up with more complex datasets. In this particular case we used the [10clusters dataset](http://www.ifs.tuwien.ac.at/dm/somtoolbox/datasets.html) and once again trained a 100x60 SOM with the Java SOMToolbox. Because of the large numer of components, we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_clusters_viz():\n",
    "    smap = SOMToolBox_Parse(path.join('pretrained', '10clusters', '10clusters_large.wgt.gz'))\n",
    "    smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "    return SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)\n",
    "\n",
    "viz_clusters = ten_clusters_viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_clusters.metro(\n",
    "    stops=7,\n",
    "    water_level=0.2,\n",
    "    overlap_shift=1,\n",
    "    #corner_penalties=[0, 0, 0, 0, 0],\n",
    "    snapping_overlay=True,\n",
    "    linewidth=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
