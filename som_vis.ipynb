{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "from os import path\n",
    "import pickle\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# SOMToolBox_Parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "# MetroSolver\n",
    "import itertools\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# MiniSOM\n",
    "import minisom as som\n",
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# SOMViz\n",
    "from scipy.spatial import distance_matrix, distance\n",
    "from ipywidgets import Layout, HBox, Box, widgets, interact\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.colors\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Set the log level\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOMToolBox_Parse:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def read_weight_file(self,):\n",
    "        df = pd.DataFrame()\n",
    "        if self.filename[-3:len(self.filename)] == '.gz':\n",
    "            with gzip.open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "        else:\n",
    "            with open(self.filename, 'rb') as file:\n",
    "                df, vec_dim, xdim, ydim = self._read_vector_file_to_df(df, file)\n",
    "\n",
    "        file.close()            \n",
    "        return df.astype('float64'), vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _read_vector_file_to_df(self, df, file):\n",
    "        xdim, ydim, vec_dim, position = 0, 0, 0, 0\n",
    "        for byte in file:\n",
    "            line = byte.decode('UTF-8')\n",
    "            if line.startswith('$'):\n",
    "                xdim, ydim, vec_dim = self._parse_vector_file_metadata(line, xdim, ydim, vec_dim)\n",
    "                if xdim > 0 and ydim > 0 and len(df.columns) == 0:\n",
    "                    df = pd.DataFrame(index=range(0, ydim * xdim), columns=range(0, vec_dim))\n",
    "            else:\n",
    "                if len(df.columns) == 0 or vec_dim == 0:\n",
    "                    raise ValueError('Weight file has no correct Dimensional information.')\n",
    "                position = self._parse_weight_file_data(line, position, vec_dim, df)\n",
    "        return df, vec_dim, xdim, ydim\n",
    "\n",
    "\n",
    "    def _parse_weight_file_data(self, line, position, vec_dim, df):\n",
    "        splitted=line.split(' ')\n",
    "        try:\n",
    "            df.values[position] = list(np.array(splitted[0:vec_dim]).astype(float))\n",
    "            position += 1\n",
    "        except: raise ValueError('The input-vector file does not match its unit-dimension.') \n",
    "        return  position\n",
    "\n",
    "\n",
    "    def _parse_vector_file_metadata(self, line, xdim, ydim, vec_dim):\n",
    "        splitted = line.split(' ')\n",
    "        if splitted[0] == '$XDIM':      xdim = int(splitted[1])\n",
    "        elif splitted[0] == '$YDIM':    ydim = int(splitted[1])\n",
    "        elif splitted[0] == '$VEC_DIM': vec_dim = int(splitted[1])\n",
    "        return xdim, ydim, vec_dim \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetroSolver:\n",
    "    \"\"\" Metro Map Solver\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, lines, input_grid, metro_grid=None, corner_penalties=[0.0, 0.7, 1.4, 4.2, 5.6]):\n",
    "        self.__lines = copy.deepcopy(lines)\n",
    "        if metro_grid is None:\n",
    "            metro_grid = input_grid\n",
    "        self.__input_grid = input_grid\n",
    "        self.__metro_grid = metro_grid\n",
    "        self.__scale = np.array([mg / ig for ig, mg in zip(self.__input_grid, self.__metro_grid)])\n",
    "\n",
    "        self.__raw_solution = None\n",
    "        self.__solution = None\n",
    "        \n",
    "        if not isinstance(corner_penalties, list):\n",
    "            raise TypeError('`penalties` has to be a list of numbers')\n",
    "        if not np.all([isinstance(i, float) or isinstance(i, int) for i in corner_penalties]):\n",
    "            raise TypeError('`penalties` has to be a list of numbers')\n",
    "        if not len(corner_penalties) == 5:\n",
    "            raise ValueError('`penalties` has to have exactly 5 elements')\n",
    "        self.__corner_penalties = corner_penalties\n",
    "\n",
    "\n",
    "    def __transform(self, input_data):\n",
    "        \"\"\" Transform into metro grid coordinates\n",
    "        \n",
    "        Utility function to transform a list of lines from input grid coordinates into \n",
    "        metro grid coordinates.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data, list):\n",
    "            return [self.__scale * line for line in input_data]\n",
    "        elif isinstance(input_data, np.ndarray):\n",
    "            return self.__scale * input_data\n",
    "        else:\n",
    "            raise ValueError(f'Transforming the coordinates contained in a {type(input_data)}'\n",
    "                             ' is currently not supported.')\n",
    "\n",
    "\n",
    "    def __inverse_transform(self, input_data):\n",
    "        \"\"\" Transform into input grid coordinates\n",
    "        \n",
    "        Utility function to transform a list of lines from metro grid coordinates into \n",
    "        input grid coordinates.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data, list):\n",
    "            return [line / self.__scale for line in input_data]\n",
    "        elif isinstance(input_data, np.ndarray):\n",
    "            return input_data / self.__scale\n",
    "        else:\n",
    "            raise ValueError(f'Transforming the coordinates contained in a {type(input_data)}'\n",
    "                             ' is currently not supported.')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __neighborhood_generator():\n",
    "        \"\"\"Sequentially point generator\n",
    "        \n",
    "        Here we generate 2D points at discrete positions starting from the origin.\n",
    "        The generated points are spiraling outwards towards infinity.\n",
    "        \"\"\"\n",
    "        r = 1\n",
    "        pos = np.array([0,0])\n",
    "        directions = [np.array([1,0]), np.array([0,-1]), np.array([-1,0]), np.array([0,1])]\n",
    "        d_idx = 0\n",
    "        yield pos\n",
    "        pos = np.array([0,r])\n",
    "        yield pos\n",
    "        while True:\n",
    "            if np.abs(pos[0]) == np.abs(pos[1]): # corner\n",
    "                if d_idx == 3: # completed 4th direction\n",
    "                    r += 1\n",
    "                    d_idx = 0\n",
    "                    pos[1] = r\n",
    "                    yield pos\n",
    "                    continue\n",
    "                d_idx += 1\n",
    "            pos = pos + directions[d_idx]\n",
    "            yield pos\n",
    "\n",
    "\n",
    "    def __gen_neighbors(self, pt, n_neighbors = 5):\n",
    "        neighbors = []\n",
    "        nearest = np.round(pt)\n",
    "\n",
    "        for offset in self.__neighborhood_generator():\n",
    "            new_pt = nearest + offset\n",
    "\n",
    "            neighbors.append((new_pt, np.linalg.norm(new_pt-pt)))\n",
    "            if len(neighbors) >= n_neighbors:\n",
    "                break\n",
    "\n",
    "        neighbors.sort(key=lambda a: a[1])\n",
    "        return neighbors\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_sector(v1, v2):\n",
    "        \"\"\" Returns the octilinear sector of v2 relative to v1\n",
    "        \n",
    "        Determines the octilinear sector of v2 relative to v1. The code is based\n",
    "        on a similar calculation in the MetroMapVisualizer.java which is part of\n",
    "        the Java SOMToolbox (http://www.ifs.tuwien.ac.at/dm/somtoolbox/index.html)\n",
    "        \n",
    "        The numbering of the different sectors is as follows (v1 in the center):\n",
    "            3  2  1\n",
    "            4 -1  0\n",
    "            5  6  7\n",
    "        \"\"\"\n",
    "\n",
    "        if v1[0] < v2[0] and v1[1] == v2[1]:   # right\n",
    "            return 0\n",
    "        elif v1[0] < v2[0] and v1[1] < v2[1]:  # right up\n",
    "            return 1\n",
    "        elif v1[0] == v2[0] and v1[1] < v2[1]: # up\n",
    "            return 2\n",
    "        elif v1[0] > v2[0] and v1[1] < v2[1]:  # left up\n",
    "            return 3\n",
    "        elif v1[0] > v2[0] and v1[1] == v2[1]: # left\n",
    "            return 4\n",
    "        elif v1[0] > v2[0] and v1[1] > v2[1]:  # left down\n",
    "            return 5\n",
    "        elif v1[0] == v2[0] and v1[1] > v2[1]: # down\n",
    "            return 6\n",
    "        elif v1[0] < v2[0] and v1[1] > v2[1]:  # right down\n",
    "            return 7\n",
    "        if np.any(v1 != v2):\n",
    "            print(v1, v2)\n",
    "\n",
    "        # points equal\n",
    "        return -1 \n",
    "\n",
    "\n",
    "    def __calc_penalty(self, sector_diff):\n",
    "        \"\"\" Calculate a penalty for line bends\n",
    "        \n",
    "        Calculates a penalty based on the sector difference of two edges.\n",
    "        A penalty of 3 makes the specific configuration as undesirable as a node\n",
    "        that's 3 cells apart. Closer solutions are favored in the final selection.\n",
    "        \"\"\"\n",
    "        if sector_diff == 4:\n",
    "            return self.__corner_penalties[4]\n",
    "\n",
    "        sector_diff = np.mod(sector_diff, 4)\n",
    "        if sector_diff == 0:\n",
    "            return self.__corner_penalties[0]\n",
    "        elif sector_diff == 1:\n",
    "            return self.__corner_penalties[1]\n",
    "        elif sector_diff == 2:\n",
    "            return self.__corner_penalties[2]\n",
    "        elif sector_diff == 3:\n",
    "            return self.__corner_penalties[3]\n",
    "\n",
    "\n",
    "    def __gen_feasible_neighbors(self, snapped, pt, n_neighbors = 4):\n",
    "        # search more neighbors than return, increases quality of neighbors with a \n",
    "        # relatively small additional computational effort\n",
    "        MULTIPLIER = 2\n",
    "\n",
    "        neighbors = []\n",
    "        nearest = np.round(pt)\n",
    "        prev = snapped[-1]\n",
    "\n",
    "        prev_direction = None\n",
    "        prev_sector = None\n",
    "        if len(snapped) > 1:\n",
    "            prev_sector = self.__get_sector(snapped[-2], snapped[-1])\n",
    "\n",
    "        for offset in self.__neighborhood_generator():\n",
    "            new_pt = nearest + offset\n",
    "\n",
    "            diff = np.abs(new_pt - prev)\n",
    "            if new_pt[0] == prev[0] or new_pt[1] == prev[1] or diff[0] == diff[1]:\n",
    "                penalty = 0\n",
    "                if prev_sector is not None:\n",
    "                    new_sector = self.__get_sector(prev, new_pt)\n",
    "                    abs_sec_diff = np.abs(new_sector - prev_sector)\n",
    "                    penalty = self.__calc_penalty(abs_sec_diff)\n",
    "\n",
    "                dist = np.linalg.norm(new_pt - prev)\n",
    "                if dist >= 1:\n",
    "                    neighbors.append((new_pt, np.linalg.norm(new_pt - pt) + penalty))\n",
    "\n",
    "            if len(neighbors) >= n_neighbors * MULTIPLIER:\n",
    "                break\n",
    "\n",
    "        neighbors.sort(key=lambda a: a[1])\n",
    "        return neighbors[:n_neighbors]\n",
    "\n",
    "\n",
    "    def __snap_line(self, line, snapped, dist, lb):\n",
    "        if len(line) == 0:\n",
    "            return dist, snapped\n",
    "        pt = line[0]\n",
    "        best_line = None\n",
    "        best = None\n",
    "        neighbors = self.__gen_feasible_neighbors(snapped, pt)\n",
    "        for n_pt, n_dist in neighbors:\n",
    "            if (dist + n_dist) > lb:\n",
    "                continue\n",
    "            n_snapped = snapped[:]\n",
    "            n_snapped.append(n_pt)\n",
    "            total_dist, new_snapped = self.__snap_line(line[1:], n_snapped, dist + n_dist, lb)\n",
    "            if total_dist is not None and total_dist < lb:\n",
    "                lb = total_dist\n",
    "                best = total_dist\n",
    "                best_line = new_snapped\n",
    "        return best, best_line\n",
    "\n",
    "\n",
    "    def solve(self):\n",
    "        dist_threshold = 3\n",
    "        snapped_lines = []\n",
    "        lines = self.__transform(self.__lines)\n",
    "        for idx, line in enumerate(lines):\n",
    "            logging.info(f\"snapping line {idx+1}/{len(self.__lines)}\")\n",
    "            start = line[0]\n",
    "            neighbors = self.__gen_neighbors(start)\n",
    "            best_dist = 999999\n",
    "            snapped = None\n",
    "            for pt, dist in neighbors:\n",
    "                n_dist, n_snapped = self.__snap_line(line[1:], [pt], dist, best_dist)\n",
    "                if n_dist is None:\n",
    "                    continue\n",
    "                if n_dist < best_dist:\n",
    "                    #print(n_snapped)\n",
    "                    best_dist = n_dist\n",
    "                    snapped = n_snapped\n",
    "            \n",
    "            snapped_lines.append(snapped)\n",
    "\n",
    "        self.__raw_solution = snapped_lines\n",
    "\n",
    "\n",
    "    def post_process(self, overlap_shift):\n",
    "        \"\"\" Post processing\n",
    "        \n",
    "        Move overlapping metro lines so that each individual line is visible in the final\n",
    "        plot.\n",
    "        \n",
    "        TODO: Return a list of crossover stations.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.__raw_solution is None:\n",
    "            print('The solve method has to be called before any post processing can be done.')\n",
    "            return\n",
    "        \n",
    "        lines = copy.deepcopy(self.__raw_solution)\n",
    "        stations = defaultdict(lambda: np.array([0,0,0,0]))\n",
    "\n",
    "        # These vectors specify the octilinear base directions. Their index corresponds\n",
    "        # to the value of the sector.\n",
    "        orientation_vectors = [\n",
    "            np.array([1,0]),\n",
    "            np.array([1,1]),\n",
    "            np.array([0,1]),\n",
    "            np.array([-1,1]),\n",
    "            np.array([-1,0]),\n",
    "            np.array([-1,-1]),\n",
    "            np.array([0,-1]),\n",
    "            np.array([1, -1])\n",
    "        ]\n",
    "        \n",
    "        # These vectors are the normalized orthogonal directions to the first four octilinear\n",
    "        # directions.\n",
    "        inv_sqrt = 1/np.sqrt(2)\n",
    "        shift_vectors = [\n",
    "            np.array([0,1]),\n",
    "            np.sqrt(2) * np.array([0,1]),\n",
    "            np.array([-1,0]),\n",
    "            np.sqrt(2) * np.array([0,-1])\n",
    "        ]\n",
    "        \n",
    "        grid = defaultdict(lambda: [])\n",
    "        rank = {}\n",
    "        \n",
    "        for lidx, line in enumerate(lines):\n",
    "            for sidx, (a,b) in enumerate(zip(line[:-1], line[1:])):\n",
    "                orientation = self.__get_sector(a, b)\n",
    "                current = np.copy(a)\n",
    "                vector = orientation_vectors[orientation]\n",
    "                logger.debug(f\"curr: {current} vector: {vector} b {b} orientation {orientation}\")\n",
    "                \n",
    "                # First iterate over each grid point between the station a and the next station b\n",
    "                # and find the maximum number of collinear edges (edges that run in the same\n",
    "                # direction or in reverse) throughout the path between the two stations.\n",
    "                max_collinear = 0\n",
    "                while not np.all(np.isclose(current, b, rtol = 0.01)):\n",
    "                    n_collinear_edges = len(grid[(tuple(current), orientation % 4)])\n",
    "                    if n_collinear_edges > max_collinear:\n",
    "                        max_collinear = n_collinear_edges\n",
    "                    \n",
    "                    # Move to the next grid point\n",
    "                    current += vector\n",
    "\n",
    "                logger.debug(f'max shift {max_collinear}')\n",
    "                \n",
    "                # Store the maximum number of collinear lines that are associated to this particular\n",
    "                # metro line (identified by the line index lidx) and edge (identified by the first\n",
    "                # stop of that particular edge) of that metro line, as well as its orientation.\n",
    "                if (lidx, sidx, orientation % 4) in rank:\n",
    "                    i = sidx\n",
    "                    while (lidx, i, orientation % 4) in rank:\n",
    "                        if rank[(lidx, i, orientation % 4)] < max_collinear + 1:\n",
    "                            rank[(lidx, i, orientation % 4)] = max_collinear + 1\n",
    "                        i -= 1\n",
    "                else:\n",
    "                    rank[(lidx, sidx, orientation % 4)] = max_collinear + 1\n",
    "                \n",
    "                # Also update the next station's rank\n",
    "                rank[(lidx, sidx+1, orientation % 4)] = max_collinear + 1\n",
    "\n",
    "                # Then iterate over those grid points between the two consecutive stations again\n",
    "                # and this time assign the maximum number of collinear edges we obtained during the \n",
    "                # last step to the actual grid positions.\n",
    "                current = np.copy(a)\n",
    "                while not np.all(np.isclose(current, b, rtol = 0.01)):\n",
    "                    grid[(tuple(current), orientation % 4)].append(True)\n",
    "                    current += vector\n",
    "                    \n",
    "                # stations\n",
    "                transformed_pt = self.__inverse_transform(a)\n",
    "                stations[tuple(transformed_pt)][orientation % 4] = stations[tuple(transformed_pt)][orientation % 4] + 1\n",
    "                if sidx == len(line) - 2:\n",
    "                    transformed_pt = self.__inverse_transform(b)\n",
    "                    stations[tuple(transformed_pt)][orientation % 4] = stations[tuple(transformed_pt)][orientation % 4] + 1\n",
    "\n",
    "        for (lidx, s, orientation), n in rank.items():\n",
    "            if n > 1:\n",
    "                f = (n % 2) * 2 - 1\n",
    "                shift = shift_vectors[orientation] * f * int(n/2) * overlap_shift\n",
    "                lines[lidx][s] = lines[lidx][s] + self.__transform(shift)\n",
    "                \n",
    "\n",
    "        self.__solution = lines\n",
    "        self.stations = stations\n",
    "    \n",
    "    \n",
    "    def get_raw_solution(self):\n",
    "        if self.__raw_solution is not None:\n",
    "            return self.__inverse_transform(self.__raw_solution)\n",
    "        else:\n",
    "            logger.warning('Solver has yet to be run. No solution available.')\n",
    "\n",
    "\n",
    "    def get_solution(self):\n",
    "        if self.__solution is not None:\n",
    "            return self.__inverse_transform(self.__solution)\n",
    "        else:\n",
    "            logger.warning('Postprocessing has yet to be run. No solution available.')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomViz:\n",
    "    \n",
    "    def __init__(self, weights=[], m=None, n=None):\n",
    "        self.weights = weights\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        \n",
    "        # Params for the metro visualization\n",
    "        self.solver_params = None\n",
    "        self.postprocessing_params = None\n",
    "        self.lines = None\n",
    "        self.metro_lines = None\n",
    "        self.stops = None\n",
    "        self.solver = None\n",
    "        self.metro_grid = None\n",
    "        self.corner_penalties = None\n",
    "\n",
    "\n",
    "    def umatrix(self, som_map=None, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        um =np.zeros((self.m *self.n, 1))\n",
    "        neuron_locs = list()\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                neuron_locs.append(np.array([i, j]))\n",
    "        neuron_distmat = distance_matrix(neuron_locs,neuron_locs)\n",
    "\n",
    "        for i in range(self.m * self.n):\n",
    "            neighbor_idxs = neuron_distmat[i] <= 1\n",
    "            neighbor_weights = self.weights[neighbor_idxs]\n",
    "            um[i] = distance_matrix(np.expand_dims(self.weights[i], 0), neighbor_weights).mean()\n",
    "\n",
    "        if som_map is None:\n",
    "            return self.plot(um.reshape(self.m,self.n), color=color, interp=interp, title=title)    \n",
    "        else:\n",
    "            som_map.data[0].z = um.reshape(self.m,self.n)\n",
    "\n",
    "\n",
    "    def hithist(self, som_map=None, idata = [], color='RdBu', interp = \"best\", title=\"\"):\n",
    "        hist = [0] *self.n *self.m\n",
    "        for v in idata: \n",
    "            position =np.argmin(np.sqrt(np.sum(np.power(self.weights - v, 2), axis=1)))\n",
    "            hist[position] += 1    \n",
    "        \n",
    "        if som_map is None:\n",
    "            return self.plot(np.array(hist).reshape(self.m,self.n), color=color, interp=interp, title=title)        \n",
    "        else:\n",
    "            som_map.data[0].z = np.array(hist).reshape(self.m,self.n)\n",
    "\n",
    "\n",
    "    def component_plane(self, som_map=None, component=0, color=\"Viridis\", interp = \"best\", title=\"\"):\n",
    "        if som_map is None:\n",
    "            return self.plot(self.weights[:,component].reshape(-1,self.n), color=color, interp=interp, title=title)   \n",
    "        else:\n",
    "            som_map.data[0].z = self.weights[:,component].reshape(-1,n)\n",
    "\n",
    "\n",
    "    def __gen_sequential_colors(self, levels, colors=px.colors.sequential.Jet):\n",
    "        \"\"\"Generate a color sequence\n",
    "        \n",
    "        Generates a color sequence with the specified number of levels based on the\n",
    "        provided continuous colormap.\n",
    "        \"\"\"\n",
    "        color_sequence = []\n",
    "        n_colors = len(colors)\n",
    "        n_levels = levels\n",
    "\n",
    "        color_sequence.append(colors[0])\n",
    "\n",
    "        if n_colors > 1:\n",
    "            color_step = 1 / (n_colors - 1)\n",
    "        else:\n",
    "            return color_sequence * n_levels\n",
    "    \n",
    "        for i in range(1, n_levels-1):\n",
    "            level_pos = i / (n_levels - 1)\n",
    "            color_index = int(level_pos/color_step)\n",
    "\n",
    "            intermediate = (level_pos - color_index * color_step)/color_step\n",
    "            color_sequence.append(plotly.colors.find_intermediate_color(colors[color_index], colors[color_index+1], intermediate, colortype='rgb'))\n",
    "\n",
    "        color_sequence.append(colors[-1])\n",
    "        return color_sequence\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_crossover_station_shape(pos=np.array([0,0]), scale=1, lines_per_sector=np.array([1,0,0,0])):\n",
    "        leading_sectors = np.argwhere(lines_per_sector == np.max(lines_per_sector)).flatten()\n",
    "        print(f\"leading: {leading_sectors}\")\n",
    "        \n",
    "        sector = 0\n",
    "        if len(leading_sectors) == 1:\n",
    "            sector = (leading_sectors[0] + 2) % 4\n",
    "        elif len(leading_sectors) == 2:\n",
    "            secdiff = np.abs(leading_sectors[0] - leading_sectors[1]) % 3\n",
    "            print(f\"secdiff: {secdiff}\")\n",
    "            if secdiff == 0:\n",
    "                sector = (leading_sectors[0] + 2) % 4\n",
    "            elif secdiff == 1:\n",
    "                sector = np.where(lines_per_sector != lines_per_sector[leading_sectors[0]])[0][0]\n",
    "            elif secdiff == 2:\n",
    "                sector = (leading_sectors[0] + 1) % 4\n",
    "        if len(leading_sectors) == 3:\n",
    "            sector = np.argmin(lines_per_sector)\n",
    "            \n",
    "        print(f'lps: {lines_per_sector}')\n",
    "        print(f\"sector: {sector}\")\n",
    "\n",
    "        w = 1\n",
    "        h = .5\n",
    "        r = np.min([0.3, h/2, w/2])\n",
    "\n",
    "        p = np.array([\n",
    "            [-w/2+r, -h/2  ],\n",
    "            [w/2-r,  -h/2  ],\n",
    "            [w/2,    -h/2  ],\n",
    "            [w/2,    -h/2+r],\n",
    "            [w/2,    h/2-r ],\n",
    "            [w/2,    h/2   ],\n",
    "            [w/2-r,  h/2   ],\n",
    "            [-w/2+r, h/2   ],\n",
    "            [-w/2,   h/2   ],\n",
    "            [-w/2,   h/2-r ],\n",
    "            [-w/2,   -h/2+r],\n",
    "            [-w/2,   -h/2  ],\n",
    "            [-w/2+r, -h/2  ],\n",
    "        ])\n",
    "\n",
    "        sector_to_degree = {\n",
    "            0: -90,\n",
    "            1: 45,\n",
    "            2: 0,\n",
    "            3: -45,\n",
    "        }\n",
    "\n",
    "        phi = np.radians(sector_to_degree[sector % 4])\n",
    "\n",
    "        A = np.array([\n",
    "            [np.cos(phi), -np.sin(phi)],\n",
    "            [np.sin(phi), np.cos(phi)],\n",
    "        ])\n",
    "\n",
    "        p = pos + scale*(A@(p.T)).T\n",
    "\n",
    "        return f\"\"\"\n",
    "                M {p[0,0]} {p[0,1]}\n",
    "                L {p[1,0]} {p[1,1]}\n",
    "                Q {p[2,0]} {p[2,1]} {p[3,0]} {p[3,1]}\n",
    "                L {p[4,0]} {p[4,1]}\n",
    "                Q {p[5,0]} {p[5,1]} {p[6,0]} {p[6,1]}\n",
    "                L {p[7,0]} {p[7,1]}\n",
    "                Q {p[8,0]} {p[8,1]} {p[9,0]} {p[9,1]}\n",
    "                L {p[10,0]} {p[10,1]}\n",
    "                Q {p[11,0]} {p[11,1]} {p[0,0]} {p[0,1]}\n",
    "                Z\"\"\"\n",
    "\n",
    "\n",
    "    def __prepare_metro(self, stops, metro_grid, corner_penalties, postprocess, overlap_shift):\n",
    "        if self.lines is None or stops != self.stops:\n",
    "            self.lines = []\n",
    "            n_lines = self.weights.shape[1]\n",
    "            for component in range(n_lines):\n",
    "                # Reshape the weights into a 2D array with the dimension (m, n)\n",
    "                raw = self.weights[:,component].reshape(self.m, self.n)\n",
    "                # Create a list of values that uniformly divide the range between the\n",
    "                # minimum and the maximum value of the component weights into 'stops'\n",
    "                # intervals.\n",
    "                ranges = np.linspace(raw.min(), raw.max(), stops)\n",
    "                # Digitize the weights array, so that only 'stops' different values\n",
    "                # are possible. The value of each element in the resulting grid\n",
    "                # corresponds to the index of the interval, starting with 1.\n",
    "                binned = np.digitize(raw, ranges)\n",
    "                \n",
    "                stations = []\n",
    "                for i in range(1, stops+1):\n",
    "                    # Find the positions inside the digitized array, where the elements\n",
    "                    # have the value of the current level i\n",
    "                    match = np.argwhere(binned == i)\n",
    "                    if match.shape[0] == 0:\n",
    "                        logging.info(\"layer empty\")\n",
    "                        continue\n",
    "                    # Summing up all matches from above, which are provided as an array of\n",
    "                    # coordinates, and dividing them by the number of matches gives us the\n",
    "                    # center of gravity for that particular level.\n",
    "                    stations.append(np.sum(match, axis=0)/match.shape[0])\n",
    "                self.lines.append(stations)\n",
    "\n",
    "        solver_activated = False\n",
    "        if stops != self.stops or metro_grid != self.metro_grid or corner_penalties != self.corner_penalties:\n",
    "            logger.info('Solving...')\n",
    "\n",
    "            self.solver = MetroSolver(lines=self.lines, input_grid=(self.m, self.n), metro_grid=metro_grid)\n",
    "            self.solver.solve()\n",
    "            solver_activated = True\n",
    "\n",
    "        if postprocess == True and (solver_activated == True or overlap_shift != self.overlap_shift):\n",
    "            logger.info('Postprocessing ...')\n",
    "            self.solver.post_process(overlap_shift=overlap_shift)\n",
    "\n",
    "        if postprocess:\n",
    "            self.metro_lines = self.solver.get_solution()\n",
    "        else:\n",
    "            self.metro_lines = self.solver.get_raw_solution()\n",
    "\n",
    "        self.stops = stops\n",
    "        self.metro_grid = metro_grid\n",
    "        self.overlap_shift = overlap_shift\n",
    "        self.corner_penalties = corner_penalties\n",
    "\n",
    "\n",
    "    def metro(self, som_map=None, stops=6, water_level=0.33, snapping_overlay=True, metro_grid=(10,10), corner_penalties=None, postprocess=True, overlap_shift=0.5):\n",
    "        water_level = np.clip(water_level, 0, 1)\n",
    "        water = [\n",
    "            (0.0, 'rgb(255,255,255)'),\n",
    "            (water_level, 'rgb(255,255,255)'),\n",
    "            (water_level, 'rgb(198,219,239)'),\n",
    "            (1.0, 'rgb(198,219,239)')\n",
    "        ]\n",
    "\n",
    "        self.__prepare_metro(stops, metro_grid, corner_penalties, postprocess, overlap_shift)\n",
    "\n",
    "        if som_map is None:\n",
    "            som_map = self.umatrix(color=water, interp='best', title='U-matrix SOMToolBox') \n",
    "\n",
    "        colors = self.__gen_sequential_colors(len(self.lines), colors=px.colors.diverging.Portland)\n",
    "        \n",
    "        if not snapping_overlay:\n",
    "            for i, (line, col) in enumerate(zip(self.lines, colors)):\n",
    "                y, x = list(zip(*line))\n",
    "                som_map.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name=f'Component {i}', line_shape='linear', line=dict(dash='dot', color=col)))\n",
    "        else:\n",
    "            for i, (line, col) in enumerate(zip(self.metro_lines, colors)):\n",
    "                y, x = list(zip(*line))\n",
    "                som_map.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name=f'Component {i}', line_shape='linear', line=dict(width=6, color=col), marker=dict(size=5, color='white', line=dict(width=2, color='black'))))\n",
    "                # Add special markers to the endstop corresponding to the highest component value\n",
    "                som_map.add_trace(go.Scatter(x=[x[0]], y=[y[0]], mode='markers', marker_symbol='circle-x', showlegend=False, line=dict(width=6, color=col), marker=dict(size=10, line=dict(width=2,color='black'))))\n",
    "\n",
    "\n",
    "            shapes = []\n",
    "            for (y, x), station_sizes in self.solver.stations.items():\n",
    "                abs_size = np.sum(station_sizes)\n",
    "\n",
    "                if abs_size > 1:\n",
    "                    shapes.append(\n",
    "                        dict(\n",
    "                            type=\"path\",\n",
    "                            path=self.generate_crossover_station_shape(pos=np.array([x, y]),\n",
    "                                                                       scale=np.array([self.m/16, self.n/16]),\n",
    "                                                                       lines_per_sector=station_sizes),\n",
    "                            line_color=\"black\",\n",
    "                            fillcolor=\"white\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "            if shapes:\n",
    "                som_map.update_layout(shapes=shapes)\n",
    "        return som_map\n",
    "\n",
    "\n",
    "    def plot(self, matrix, color=\"Viridis\",interp = \"none\", title=\"\", showscale=False):\n",
    "        return go.FigureWidget(go.Heatmap(z=matrix, zsmooth=interp, showscale=showscale, colorscale=color), layout=go.Layout(width=700, height=700,title=title, title_x=0.5, plot_bgcolor='rgb(255,255,255)'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniSOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaton\n",
    "m = 40\n",
    "n = 20\n",
    "\n",
    "# Pre-Process dataset\n",
    "iris = datasets.load_iris().data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "iris = min_max_scaler.fit_transform(iris)\n",
    "\n",
    "# Train SOM\n",
    "s = som.MiniSom(m, n, iris.shape[1], sigma=0.8, learning_rate=0.7)\n",
    "s.train_random(iris, 10000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.load(open(path.join('pretrained', 'overlapping_som.p'), 'rb'))\n",
    "m = 20\n",
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaton\n",
    "viz = SomViz(s._weights.reshape(-1,4), m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    viz.metro(\n",
    "        stops=7,\n",
    "        water_level=0.2,\n",
    "        metro_grid=(10, 10),\n",
    "        overlap_shift=0.2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from SOMToolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmap = SOMToolBox_Parse(path.join('pretrained', 'iris', 'iris.vec'))\n",
    "idata, idim, idata_x, idata_y = trainedmap.read_weight_file()\n",
    "\n",
    "smap = SOMToolBox_Parse(path.join('pretrained', 'iris', 'iris.wgt.gz'))\n",
    "smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "\n",
    "# Visualizaton\n",
    "viz_iris = SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    viz_iris.metro(\n",
    "        stops=7,\n",
    "        water_level=0.3,\n",
    "        metro_grid=(10, 10),\n",
    "        overlap_shift=0.15,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmap = SOMToolBox_Parse(path.join('pretrained', '10clusters', '10clusters.vec'))\n",
    "idata, idim, idata_x, idata_y = trainedmap.read_weight_file()\n",
    "\n",
    "smap = SOMToolBox_Parse(path.join('pretrained', '10clusters', '10clusters.wgt'))\n",
    "smap, sdim, smap_x, smap_y = smap.read_weight_file()\n",
    "\n",
    "# Visualizaton\n",
    "viz_10clusters = SomViz(smap.values.reshape(-1,sdim), smap_y, smap_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    viz_10clusters.metro(\n",
    "        stops=7,\n",
    "        water_level=0.3,\n",
    "        metro_grid=(10, 10),\n",
    "        overlap_shift=0.2,\n",
    "        postprocess=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmap = SOMToolBox_Parse(path.join('pretrained', 'chainlink', 'chainlink.vec'))\n",
    "idata, idim, idata_x, idata_y = trainedmap.read_weight_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaton\n",
    "m = 40\n",
    "n = 20\n",
    "\n",
    "# Pre-Process dataset\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dat = min_max_scaler.fit_transform(idata)\n",
    "\n",
    "# Train SOM\n",
    "s = som.MiniSom(m, n, idata.shape[1], sigma=0.8, learning_rate=0.7)\n",
    "s.train_random(dat, 1000000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaton\n",
    "viz_chainlink = SomViz(s._weights.reshape(-1,3), 40, 20)\n",
    "display(viz_chainlink.umatrix())\n",
    "display(viz_chainlink.metro(stops=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
